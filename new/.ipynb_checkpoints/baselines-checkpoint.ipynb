{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, time\n",
    "from sklearn.metrics import mean_absolute_error as MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('./epinions_subset/user_mapping.json')\n",
    "user_mapping = json.loads(f.read())\n",
    "f.close()\n",
    "f = open('./epinions_subset/item_mapping.json')\n",
    "item_mapping = json.loads(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def five_fold_split(matrix):\n",
    "    split_matrices = []\n",
    "    valid_indices = matrix.nonzero()\n",
    "    test_set_size = int(0.2 * len(valid_indices[0]))\n",
    "    for i in range(5):\n",
    "        start = int(i * 0.2 * len(valid_indices[0]))\n",
    "        end = int((i+1) * 0.2 * len(valid_indices[0]))\n",
    "        test_indices = (valid_indices[0][start:end], valid_indices[1][start:end])\n",
    "        \n",
    "        if start > 0 and end < len(valid_indices[0]):\n",
    "            train_indices = (np.append(valid_indices[0][0:start], valid_indices[0][end:len(valid_indices[0])]),\n",
    "                                       np.append(valid_indices[1][0:start], valid_indices[1][end:len(valid_indices[0])]) )\n",
    "        elif start > 0:\n",
    "            train_indices = (valid_indices[0][0:start], valid_indices[1][0:start])\n",
    "        elif end < len(valid_indices[0]):\n",
    "            train_indices = (valid_indices[0][end:len(valid_indices[0])], valid_indices[1][end:len(valid_indices[0])])\n",
    "        \n",
    "        train_matrix = np.zeros(matrix.shape)\n",
    "        train_matrix[train_indices] = matrix[train_indices]\n",
    "        test_matrix = np.zeros(matrix.shape)\n",
    "        test_matrix[test_indices] = matrix[test_indices]\n",
    "        split_matrices.append((train_matrix, test_matrix))\n",
    "    count = 0\n",
    "    for tup in split_matrices:\n",
    "        print (len(valid_indices[0]), len(tup[0].nonzero()[0]) + len(tup[1].nonzero()[0]))\n",
    "    return split_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_item_based(user_by_item):\n",
    "    print (user_by_item.shape)\n",
    "    mask = np.ones(user_by_item.shape)\n",
    "    mask[user_by_item.nonzero()] = 0\n",
    "    masked_matrix = np.ma.masked_array(user_by_item, mask=mask)\n",
    "    return np.ma.corrcoef(masked_matrix, rowvar=False).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_user_based(user_by_item):\n",
    "    item_by_user = user_by_item.T\n",
    "    print (item_by_user.shape)\n",
    "    mask = np.ones(item_by_user.shape)\n",
    "    mask[item_by_user.nonzero()] = 0\n",
    "    masked_matrix = np.ma.masked_array(item_by_user, mask=mask)\n",
    "    return np.ma.corrcoef(masked_matrix, rowvar=False).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68640 68640\n",
      "68640 68640\n",
      "68640 68640\n",
      "68640 68640\n",
      "68640 68640\n"
     ]
    }
   ],
   "source": [
    "user_item_matrix = np.loadtxt('./epinions_subset/user_item_matrix.txt')\n",
    "split_matrices = five_fold_split(user_item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(3000, 1000)\n",
      "1\n",
      "(3000, 1000)\n",
      "2\n",
      "(3000, 1000)\n",
      "3\n",
      "(3000, 1000)\n",
      "4\n",
      "(3000, 1000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (i)\n",
    "    item_similarity = train_item_based(split_matrices[i][0])\n",
    "    np.savetxt('./epinions_subset/item_similarity_%d.txt'%i, item_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nmae_item_item(test_matrix, train_matrix, similarity_matrix):\n",
    "    indices = test_matrix.nonzero()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i,j in zip(indices[0], indices[1]):\n",
    "        y_true.append(test_matrix[i][j])\n",
    "        item_sum = np.sum(similarity_matrix[j]) - 1\n",
    "        if item_sum == 0:\n",
    "            predicted_rating = np.mean(train_matrix[:,j][train_matrix[:,j].nonzero()])\n",
    "        else:\n",
    "            predicted_rating = np.mean(train_matrix[:,j][train_matrix[:,j].nonzero()]) + np.dot(similarity_matrix[j].flatten(), train_matrix[i].flatten())/item_sum\n",
    "        y_pred.append(np.round(predicted_rating))\n",
    "    return MAE(y_true, y_pred)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.211137820513\n",
      "0.218440413753\n",
      "0.210099796037\n",
      "0.213414189977\n",
      "0.215417395105\n"
     ]
    }
   ],
   "source": [
    "##prediction item item\n",
    "for i in range(5):\n",
    "    similarity = np.loadtxt('./epinions_subset/item_similarity_%d.txt'%i)\n",
    "    print (nmae_item_item(split_matrices[i][1], split_matrices[i][0], similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(1000, 3000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2ccc71fc4655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0muser_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_user_based\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_matrices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./epinions_subset/user_similarity_%d.txt'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_similarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-55065388f1f1>\u001b[0m in \u001b[0;36mtrain_user_based\u001b[0;34m(user_by_item)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_by_user\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmasked_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_by_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/vedant/anaconda3/lib/python3.6/site-packages/numpy/ma/extras.py\u001b[0m in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, allow_masked, ddof)\u001b[0m\n\u001b[1;32m   1429\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m                     _x = mask_cols(\n\u001b[0;32m-> 1431\u001b[0;31m                             vstack((x[:, i], x[:, j]))).var(axis=1)\n\u001b[0m\u001b[1;32m   1432\u001b[0m                     \u001b[0m_denom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_denom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0m_denom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vedant/anaconda3/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36mvar\u001b[0;34m(self, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m   5150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5151\u001b[0m             \u001b[0mdanom\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mdanom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5152\u001b[0;31m         \u001b[0mdvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdanom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5153\u001b[0m         \u001b[0;31m# Apply the mask if it's not a scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vedant/anaconda3/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, a, b, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;31m# Transforms to a (subclass of) MaskedArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mmasked_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_masked_subclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m         \u001b[0mmasked_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vedant/anaconda3/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__array_finalize__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m   2917\u001b[0m         \"\"\"\n\u001b[1;32m   2918\u001b[0m         \u001b[0;31m# Get main attributes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2919\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2921\u001b[0m         \u001b[0;31m# We have to decide how to initialize self.mask, based on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vedant/anaconda3/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m_update_from\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m   2903\u001b[0m                      \u001b[0m_hardmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_hardmask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                      \u001b[0m_sharedmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_sharedmask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2905\u001b[0;31m                      \u001b[0m_isfield\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_isfield'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2906\u001b[0m                      \u001b[0m_baseclass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_baseclass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_baseclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                      \u001b[0m_optinfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_optinfo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (i)\n",
    "    user_similarity = train_user_based(split_matrices[i][0])\n",
    "    np.savetxt('./epinions_subset/user_similarity_%d.txt'%i, user_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(all='raise')\n",
    "def nmae_user_user(test_matrix, train_matrix, similarity_matrix):\n",
    "    indices = test_matrix.nonzero()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i,j in zip(indices[0], indices[1]):\n",
    "        y_true.append(test_matrix[i][j])\n",
    "        user_sum = np.sum(similarity_matrix[i]) - 1\n",
    "        if user_sum == 0:\n",
    "            predicted_rating = np.mean(train_matrix[i,:][train_matrix[i,:].nonzero()])\n",
    "        elif len(train_matrix[i,:][train_matrix[i,:].nonzero()]) == 0:\n",
    "            predicted_rating = np.mean(train_matrix[:,j][train_matrix[:,j].nonzero()])\n",
    "        else:\n",
    "            numerator = 0\n",
    "            for k in range(test_matrix.shape[0]):\n",
    "                if k != i and train_matrix[k][j] != 0:\n",
    "                    if len(train_matrix[k,:][train_matrix[k,:].nonzero()]) == 0:\n",
    "                        print (train_matrix[k,:][train_matrix[k,:].nonzero()])\n",
    "                    u_a_mean = np.mean(train_matrix[k,:][train_matrix[k,:].nonzero()])\n",
    "                    numerator += similarity_matrix[i][k] * (train_matrix[k][j] - u_a_mean)\n",
    "            predicted_rating = np.mean(train_matrix[i,:][train_matrix[i,:].nonzero()]) + numerator/user_sum\n",
    "        y_pred.append(np.round(predicted_rating))\n",
    "    return MAE(y_true, y_pred)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.211119609557\n",
      "0.218895687646\n",
      "0.20915282634\n",
      "0.213395979021\n",
      "0.215362762238\n"
     ]
    }
   ],
   "source": [
    "##prediction user user\n",
    "for i in range(5):\n",
    "    similarity = np.loadtxt('./epinions_subset/user_similarity_%d.txt'%i)\n",
    "    print (nmae_user_user(split_matrices[i][1], split_matrices[i][0], similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nmae_trust(test_matrix, train_matrix, similarity_matrix, trust_matrix):\n",
    "    similarity_matrix = 0.1*similarity_matrix + 0.9*trust_matrix\n",
    "    indices = test_matrix.nonzero()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i,j in zip(indices[0], indices[1]):\n",
    "        y_true.append(test_matrix[i][j])\n",
    "        user_sum = np.sum(similarity_matrix[i]) - 1\n",
    "        if user_sum == 0:\n",
    "            predicted_rating = np.mean(train_matrix[i,:][train_matrix[i,:].nonzero()])\n",
    "        elif len(train_matrix[i,:][train_matrix[i,:].nonzero()]) == 0:\n",
    "            predicted_rating = np.mean(train_matrix[:,j][train_matrix[:,j].nonzero()])\n",
    "        else:\n",
    "            numerator = 0\n",
    "            for k in range(test_matrix.shape[0]):\n",
    "                if k != i and train_matrix[k][j] != 0:\n",
    "                    if len(train_matrix[k,:][train_matrix[k,:].nonzero()]) == 0:\n",
    "                        print (train_matrix[k,:][train_matrix[k,:].nonzero()])\n",
    "                    u_a_mean = np.mean(train_matrix[k,:][train_matrix[k,:].nonzero()])\n",
    "                    numerator += similarity_matrix[i][k] * (train_matrix[k][j] - u_a_mean)\n",
    "            predicted_rating = np.mean(train_matrix[i,:][train_matrix[i,:].nonzero()]) + numerator/user_sum\n",
    "        y_pred.append(np.round(predicted_rating))\n",
    "    return MAE(y_true, y_pred)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trustMat_E = None\n",
    "trustMat_D = None\n",
    "with h5py.File('trust_pairs.h5', 'r') as hf:\n",
    "    trustMat_E = hf['E'][:]\n",
    "    trustMat_D = hf['D'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.211119609557\n",
      "0.218895687646\n",
      "0.20915282634\n",
      "0.213395979021\n",
      "0.215362762238\n"
     ]
    }
   ],
   "source": [
    "##prediction trust user\n",
    "for i in range(5):\n",
    "    similarity = np.loadtxt('./epinions_subset/user_similarity_%d.txt'%i)\n",
    "    print (nmae_trust(split_matrices[i][1], split_matrices[i][0], similarity, trustMat_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 128)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trust_embedding = np.loadtxt(\"./epinions_subset/epinions_embed_1\", skiprows=1)\n",
    "trust_embedding.sort(axis=0)\n",
    "# padding = np.zeros((3000-trust_embedding.shape[0], trust_embedding.shape[1])) + 1\n",
    "# trust_embedding = np.concatenate((trust_embedding,padding))[:,1:]\n",
    "trust_embedding = trust_embedding[:,1:]\n",
    "trust_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 128)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bitmap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-4f76bb4ecd5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msimilarity_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0membedding_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrust_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-65-4f76bb4ecd5b>\u001b[0m in \u001b[0;36mtrain_embeddings\u001b[0;34m(user_by_movie)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#                 common_ratings_user2 = np.array(user2_movies[bitmap.astype(int)]).flatten()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbitmap\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m#                     mean_2 = np.average(user2_movies[user2_movies.nonzero()])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mmean_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser2_movies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bitmap' is not defined"
     ]
    }
   ],
   "source": [
    "def train_embeddings(user_by_movie):\n",
    "    similarity_matrix = np.zeros(user_by_movie.shape)\n",
    "    print (user_by_movie.shape)\n",
    "\n",
    "    count = 0\n",
    "    for i in range(user_by_movie.shape[0]):\n",
    "        user1_movies = np.array(user_by_movie[i].T).flatten()\n",
    "        mean_1 = np.mean(user1_movies)\n",
    "#         mean_1 = np.average(user1_movies[user1_movies.nonzero()])\n",
    "        start = time.clock()\n",
    "\n",
    "        for j in range(user_by_movie.shape[0]):\n",
    "            if i != j:\n",
    "                user2_movies = np.array(user_by_movie[j].T).flatten()\n",
    "#                 bitmap1 = user1_movies.nonzero()[0]\n",
    "#                 bitmap2 = user2_movies.nonzero()[0]\n",
    "#                 if bitmap2.shape[0] == 0:\n",
    "#                     continue\n",
    "#                 if bitmap1.shape[0] > bitmap2.shape[0]:\n",
    "#                     bitmap2 = np.concatenate( (bitmap2, np.array(np.zeros( (1, bitmap1.shape[0] - bitmap2.shape[0]) ) ).flatten() ), axis = 0)\n",
    "#                 else:\n",
    "#                     bitmap1 = np.concatenate( (bitmap1, np.array(np.zeros( (1, bitmap2.shape[0] - bitmap1.shape[0]) ) ).flatten() ), axis = 0)\n",
    "#                 bitmap = np.intersect1d(np.array(bitmap1).flatten(), np.array(bitmap2).flatten())\n",
    "#                 # print bitmap\n",
    "#                 common_ratings_user1 = np.array(user1_movies[bitmap.astype(int)]).flatten()\n",
    "#                 common_ratings_user2 = np.array(user2_movies[bitmap.astype(int)]).flatten()\n",
    "\n",
    "#                 if len(bitmap) > 0:\n",
    "#                     mean_2 = np.average(user2_movies[user2_movies.nonzero()])\n",
    "                mean_2 = np.mean(user2_movies)\n",
    "                try:\n",
    "                    user1_movies -= mean_1\n",
    "                    user2_movies -= mean_2\n",
    "                    sq_1 = np.array(np.square(user1_movies)).flatten()\n",
    "                    sq_2 = np.array(np.square(user2_movies)).flatten()\n",
    "                    s_score = np.sum( user1_movies * user2_movies )/ np.sqrt( np.sum(sq_1) * np.sum(sq_2) )\n",
    "                    similarity_matrix[i][j] = s_score\n",
    "                except Exception as e:\n",
    "                    similarity_matrix[i][j] = 0\n",
    "#                 else:\n",
    "#                     similarity_matrix[i][j] = 0\n",
    "\n",
    "        print ('Time Taken: ' + str(time.clock() - start))\n",
    "\n",
    "        count += 1\n",
    "        # if count % 10 == 0:\n",
    "        print ('\\t%d/%d'%(count,user_max))\n",
    "    return similarity_matrix\n",
    "    \n",
    "embedding_similarity = train_embeddings(trust_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
